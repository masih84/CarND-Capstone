{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing Traffic Light Labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageColor\n",
    "import time\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frozen inference graph files. NOTE: change the path to where you saved the models.\n",
    "SSD_GRAPH_FILE = './udacity_object_detection_frozen_models/ssd_mobilenet_v1_coco_11_06_2017/frozen_inference_graph.pb'\n",
    "RFCN_GRAPH_FILE = './udacity_object_detection_frozen_models/rfcn_resnet101_coco_11_06_2017/frozen_inference_graph.pb'\n",
    "FASTER_RCNN_GRAPH_FILE = './udacity_object_detection_frozen_models/faster_rcnn_inception_resnet_v2_atrous_coco_11_06_2017/frozen_inference_graph.pb'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are utility functions. The main purpose of these is to draw the bounding boxes back onto the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of colors = 148\n"
     ]
    }
   ],
   "source": [
    "# Colors (one for each class)\n",
    "cmap = ImageColor.colormap\n",
    "print(\"Number of colors =\", len(cmap))\n",
    "COLOR_LIST = sorted([c for c in cmap.keys()])\n",
    "\n",
    "#\n",
    "# Utility funcs\n",
    "#\n",
    "\n",
    "def filter_boxes(min_score, boxes, scores, classes):\n",
    "    \"\"\"Return boxes with a confidence >= `min_score`\"\"\"\n",
    "    n = len(classes)\n",
    "    idxs = []\n",
    "    for i in range(n):\n",
    "        if scores[i] >= min_score:\n",
    "            idxs.append(i)\n",
    "    \n",
    "    filtered_boxes = boxes[idxs, ...]\n",
    "    filtered_scores = scores[idxs, ...]\n",
    "    filtered_classes = classes[idxs, ...]\n",
    "    return filtered_boxes, filtered_scores, filtered_classes\n",
    "\n",
    "def to_image_coords(boxes, height, width):\n",
    "    \"\"\"\n",
    "    The original box coordinate output is normalized, i.e [0, 1].\n",
    "    \n",
    "    This converts it back to the original coordinate based on the image\n",
    "    size.\n",
    "    \"\"\"\n",
    "    box_coords = np.zeros_like(boxes)\n",
    "    box_coords[:, 0] = boxes[:, 0] * height\n",
    "    box_coords[:, 1] = boxes[:, 1] * width\n",
    "    box_coords[:, 2] = boxes[:, 2] * height\n",
    "    box_coords[:, 3] = boxes[:, 3] * width\n",
    "    \n",
    "    return box_coords\n",
    "\n",
    "def draw_boxes(image, boxes, classes, thickness=4):\n",
    "    \"\"\"Draw bounding boxes on the image\"\"\"\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    for i in range(len(boxes)):\n",
    "        bot, left, top, right = boxes[i, ...]\n",
    "        class_id = int(classes[i])\n",
    "        color = COLOR_LIST[class_id]\n",
    "        draw.line([(left, top), (left, bot), (right, bot), (right, top), (left, top)], width=thickness, fill=color)\n",
    "        \n",
    "def load_graph(graph_file):\n",
    "    \"\"\"Loads a frozen inference graph\"\"\"\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        od_graph_def = tf.GraphDef()\n",
    "        with tf.gfile.GFile(graph_file, 'rb') as fid:\n",
    "            serialized_graph = fid.read()\n",
    "            od_graph_def.ParseFromString(serialized_graph)\n",
    "            tf.import_graph_def(od_graph_def, name='')\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detection_graph = load_graph(SSD_GRAPH_FILE)\n",
    "detection_graph = load_graph(RFCN_GRAPH_FILE)\n",
    "#detection_graph = load_graph(FASTER_RCNN_GRAPH_FILE)\n",
    "\n",
    "# The input placeholder for the image.\n",
    "# `get_tensor_by_name` returns the Tensor with the associated name in the Graph.\n",
    "image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "# Each box represents a part of the image where a particular object was detected.\n",
    "detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "\n",
    "# Each score represent how level of confidence for each of the objects.\n",
    "# Score is shown on the result image, together with the class label.\n",
    "detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "\n",
    "# The classification of the object (integer id).\n",
    "detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./train/green/6417064.jpg', './train/green/8540_3.jpg', './train/green/915_8540_3.jpg', './train/green/left0541.jpg', './train/green/left0821.jpg', './train/green/session1_12.jpg', './train/green/session1_332.jpg', './train/green/session1_407.jpg', './train/green/session1_424.jpg', './train/green/session2_145.jpg', './train/green/session2_238.jpg', './train/green/session2_386.jpg', './train/green/session2_65.jpg', './train/yellow/12382030.jpg', './train/yellow/5011_8540_3.jpg', './train/yellow/left0022.jpg', './train/yellow/left0222.jpg', './train/yellow/left0228.jpg', './train/yellow/left0789.jpg', './train/yellow/left0793.jpg', './train/yellow/left0796.jpg', './train/yellow/left0798.jpg', './train/yellow/left0802.jpg', './train/red/040_8540_3.jpg', './train/red/1510399_4.jpg', './train/red/762853835.jpg', './train/red/97376060.jpg', './train/red/left0515.jpg', './train/red/left0984.jpg', './train/red/session1_259.jpg', './train/red/session1_46.jpg', './train/red/session2_119.jpg', './train/red/session2_164.jpg', './train/red/session2_181.jpg', './train/red/session2_226.jpg', './train/red/session2_237.jpg', './train/red/session2_242.jpg', './train/red/session2_285.jpg', './train/red/session2_310.jpg', './train/red/session2_330.jpg', './train/red/session2_339.jpg', './train/red/session2_355.jpg', './train/red/session2_369.jpg', './train/red/session2_399.jpg', './train/red/session2_409.jpg', './train/red/session2_418.jpg', './train/red/session2_426.jpg', './train/red/session2_437.jpg', './train/red/session2_441.jpg', './train/red/session2_80.jpg', './train/red/TrafficLight_Img.jpg', './train/no/12800_1.png', './train/no/151034382172194099_2.jpg', './train/no/151034382271619987_2.jpg', './train/no/1510344584569776058_0.jpg', './train/no/1510398.jpg', './train/no/2259851_2.png', './train/no/6890744_0.jpg', './train/no/7657595_2.jpg', './train/no/7674711_1.png', './train/no/9835983_2.jpg']\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "df = pd.DataFrame\n",
    "data_paths = ['./train/green','./train/yellow','./train/red','./train/no']\n",
    "#data_paths = ['./train/no']\n",
    "process_path = './train/processed'\n",
    "images_name = []\n",
    "proccessed_names = []\n",
    "data_labels = []\n",
    "for i,data_path in enumerate(data_paths):\n",
    "    images = os.listdir(data_path)\n",
    "    #print(images)\n",
    "    for image in images:\n",
    "        images_name.append(data_path+'/'+image)\n",
    "        proccessed_names.append(process_path+'/'+image)\n",
    "        data_labels.append(i+1)\n",
    "\n",
    "print(images_name)\n",
    "print(data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10. 10. 10. 10.]\n",
      "[0.99659806 0.99539596 0.98103255 0.9810168 ]\n",
      "[10. 10. 10.]\n",
      "[0.9934155 0.9914916 0.9846528]\n",
      "[10. 10. 10.]\n",
      "[0.9964785  0.98997235 0.98877037]\n",
      "[10. 10. 10. 10. 10.]\n",
      "[0.99158925 0.99149513 0.9892511  0.943068   0.93195873]\n",
      "[10. 10.]\n",
      "[0.9850987  0.97903216]\n",
      "[10. 10. 10.]\n",
      "[0.9956666  0.99498206 0.978017  ]\n",
      "[10. 10. 10.]\n",
      "[0.98498327 0.9828651  0.98222303]\n",
      "[10. 10. 10.]\n",
      "[0.9863323  0.9836617  0.98141885]\n",
      "[10.]\n",
      "[0.9925754]\n",
      "[10.]\n",
      "[0.81753546]\n",
      "[10. 10.]\n",
      "[0.9910517 0.9899188]\n",
      "[10. 10. 10.  1.]\n",
      "[0.9830199  0.9679233  0.9217663  0.84473544]\n",
      "[10. 10. 10.]\n",
      "[0.98566955 0.97603446 0.95653236]\n",
      "[10. 10. 10.]\n",
      "[0.9928087 0.9905318 0.9885514]\n",
      "[10. 10.]\n",
      "[0.981927  0.9727456]\n",
      "[10. 10. 10.]\n",
      "[0.99513644 0.994799   0.9881188 ]\n",
      "[10. 10.]\n",
      "[0.9915535 0.9863673]\n",
      "[10.]\n",
      "[0.98754984]\n",
      "[10. 10. 10.]\n",
      "[0.9952892  0.99481285 0.99368805]\n",
      "[10. 10. 10.]\n",
      "[0.99743646 0.9959202  0.99440926]\n",
      "[10. 10. 10.]\n",
      "[0.9959254  0.9959078  0.99107707]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\masih\\anaconda2\\envs\\tf12\\lib\\site-packages\\matplotlib\\pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10. 10.]\n",
      "[0.9966376 0.9926555]\n",
      "[10. 10.]\n",
      "[0.99676114 0.9904392 ]\n",
      "[10. 10. 10.  1.]\n",
      "[0.9835723  0.97836316 0.96637416 0.91265976]\n",
      "[10. 10. 10.]\n",
      "[0.9865862  0.98096037 0.9348059 ]\n",
      "[10. 10. 10.]\n",
      "[0.99501306 0.99390775 0.9937953 ]\n",
      "[10. 10. 10. 10.]\n",
      "[0.9972216  0.99328643 0.9920277  0.98806727]\n",
      "[10. 10. 10. 10.]\n",
      "[0.9958703  0.98778266 0.98564154 0.97558707]\n",
      "[10. 10. 10. 10.]\n",
      "[0.9897641 0.9883152 0.9800222 0.8925247]\n",
      "[10.]\n",
      "[0.8982414]\n",
      "[10. 10. 10.]\n",
      "[0.98837495 0.9583291  0.9174695 ]\n",
      "[10. 10. 10.]\n",
      "[0.9892714 0.9681977 0.9439245]\n",
      "[10. 10. 10.]\n",
      "[0.9911742  0.98895776 0.9823124 ]\n"
     ]
    }
   ],
   "source": [
    "# Load a sample image.\n",
    "#image = Image.open('./assets/sample1.jpg')\n",
    "#'./train/green/915_8540_3.jpg'\n",
    "# image_name = './train/yellow/left0789.jpg'\n",
    "#'./train/red/040_8540_3.jpg'\n",
    "total_boxes = []\n",
    "for i, image_name in enumerate(images_name):\n",
    "    #image_name = './train/yellow/left0789.jpg'\n",
    "    image = Image.open(image_name)\n",
    "    image_np = np.expand_dims(np.asarray(image, dtype=np.uint8), 0)\n",
    "    with tf.Session(graph=detection_graph) as sess:                \n",
    "        # Actual detection.\n",
    "        (boxes, scores, classes) = sess.run([detection_boxes, detection_scores, detection_classes], \n",
    "                                            feed_dict={image_tensor: image_np})\n",
    "\n",
    "        # Remove unnecessary dimensions\n",
    "        boxes = np.squeeze(boxes)\n",
    "        scores = np.squeeze(scores)\n",
    "        classes = np.squeeze(classes)\n",
    "\n",
    "        confidence_cutoff = 0.8\n",
    "        # Filter boxes with a confidence score less than `confidence_cutoff`\n",
    "        boxes, scores, classes = filter_boxes(confidence_cutoff, boxes, scores, classes)\n",
    "\n",
    "        # The current box coordinates are normalized to a range between 0 and 1.\n",
    "        # This converts the coordinates actual location on the image.\n",
    "        width, height = image.size\n",
    "        box_coords = to_image_coords(boxes, height, width)\n",
    "        total_boxes.append(box_coords)\n",
    "        # Each class with be represented by a differently colored box\n",
    "        draw_boxes(image, box_coords, classes)\n",
    "        print(classes)\n",
    "        print(scores)\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(image) \n",
    "        plt.savefig(proccessed_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "print(box_coords)\n",
    "class_dict = {\n",
    "    1: 'green', # List of class map Text with byte\n",
    "    2: 'yellow'\n",
    "}\n",
    "print(class_dict[1])\n",
    "print(total_yellow_boxes[2])\n",
    "'''\n",
    "images = []\n",
    "c = np.empty([1,5])\n",
    "#print(c)\n",
    "i = -1\n",
    "for one_image_boxs,image_name in zip(total_boxes,images_name):\n",
    "    i = i+1\n",
    "    for box in one_image_boxs:\n",
    "        b2 = box\n",
    "        b2 = np.append(b2,[data_labels[i]])\n",
    "        #print(b2)\n",
    "        c = np.vstack([c,b2])\n",
    "        images.append(image_name)\n",
    "    \n",
    "file_name = './train/processed/labeld_data.csv'\n",
    "#c.reshape((5,3))\n",
    "c = np.delete(c, (0), axis=0)\n",
    "print(c)\n",
    "sz = np.size(c)/5\n",
    "print(sz)\n",
    "d = np.asarray(images).reshape((145,1))\n",
    "print(len(c))\n",
    "print(len(d))\n",
    "\n",
    "df = pd.DataFrame(c)\n",
    "df['b'] = d\n",
    "df.to_csv(file_name)\n",
    "#e = np.column_stack([c,d[:,1]])\n",
    "print(images)\n",
    "#a = numpy.asarray([ [1,2,3], [4,5,6], [7,8,9] ])\n",
    "#np.savetxt(file_name, c, delimiter=\",\", fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
